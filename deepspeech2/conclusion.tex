\section{Conclusion}

End-to-end deep learning presents the exciting opportunity to improve speech
recognition systems continually with increases in data and computation.
Indeed, our results show that, compared to the previous incarnation, Deep
Speech has significantly closed the gap in transcription performance with human
workers by leveraging more data and larger models. Further, since the approach
is highly generic, we've shown that it can quickly be applied to new languages.
Creating high-performing recognizers for two very different languages, English
and Mandarin, required essentially no expert knowledge of the languages.
Finally, we have also shown that this approach can be efficiently deployed by
batching user requests together on a GPU server, paving the way to deliver
end-to-end Deep Learning technologies to users. 

To achieve these results, we have explored various network architectures,
finding several effective techniques: enhancements to numerical optimization
through SortaGrad and Batch Normalization, evaluation of RNNs with larger
strides with bigram outputs for English, searching through both bidirectional
and unidirectional models. This exploration was powered by a well optimized,
High Performance Computing inspired training system that allows us to train
new, full-scale models on our large datasets in just a few days.

Overall, we believe our results confirm and exemplify the value of end-to-end
Deep Learning methods for speech recognition in several settings. In those
cases where our system is not already comparable to humans, the difference has
fallen rapidly, largely because of application-agnostic Deep Learning
techniques. We believe these techniques will continue to scale, and thus
conclude that the vision of a single speech system that outperforms humans in
most scenarios is imminently achievable.
