\section{Conclusion}

We have presented an end-to-end deep learning-based speech system capable of
outperforming existing state-of-the-art recognition pipelines in two
challenging scenarios: clear, conversational speech and speech in noisy
environments. Our approach is enabled particularly by multi-GPU training and by
data collection and synthesis strategies to build large training sets
exhibiting the distortions our system must handle (such as background noise and
Lombard effect). Combined, these solutions enable us to build a data-driven
speech system that is at once better performing than existing methods while no
longer relying on the complex processing stages that had stymied further
progress. We believe this approach will continue to improve as we capitalize on
increased computing power and dataset sizes in the future.
